{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Patter with Semantic Kernel\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install semantic-kernel==1.37.0 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load environment variables from a .env file if present\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Annotated\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    "    OpenAIChatPromptExecutionSettings,\n",
    ")\n",
    "from semantic_kernel.connectors.in_memory import InMemoryCollection\n",
    "from semantic_kernel.data.vector import VectorStoreField, vectorstoremodel\n",
    "from semantic_kernel.functions import KernelArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock paragraph data - sample documents about AI topics\n",
    "MOCK_DOCUMENTS = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans. AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of achieving its goals.\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that focuses on the development of algorithms and statistical models that enable computer systems to improve their performance on a specific task through experience. Deep learning, a subset of machine learning, uses neural networks with multiple layers to progressively extract higher-level features from raw input.\n",
    "\n",
    "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language. NLP is used to apply algorithms to identify and extract the natural language rules such that the unstructured language data is converted into a form that computers can understand.\n",
    "\n",
    "Computer vision is an interdisciplinary scientific field that deals with how computers can gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to understand and automate tasks that the human visual system can do. Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images.\n",
    "\n",
    "Reinforcement learning is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.\n",
    "\n",
    "Neural networks are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn to perform tasks by considering examples, generally without being programmed with task-specific rules. For instance, in image recognition, they might learn to identify images that contain cats by analyzing example images.\n",
    "\n",
    "Generative AI refers to artificial intelligence systems capable of generating text, images, or other media in response to prompts. Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics. Examples include large language models like GPT and image generation models like DALL-E.\n",
    "\n",
    "The Transformer architecture is a neural network architecture that has become the foundation for many modern AI models. It uses self-attention mechanisms to process input data in parallel, making it highly efficient for tasks like language translation and text generation. Transformers have revolutionized natural language processing since their introduction in 2017.\n",
    "\"\"\"\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "text_embedding = AzureTextEmbedding(service_id=\"embedding\", api_key=api_key, endpoint=endpoint, deployment_name=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data class that will store the text chunk and the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorstoremodel(collection_name=\"documents\")\n",
    "@dataclass\n",
    "class DocumentParagraph:\n",
    "    id: Annotated[str, VectorStoreField(\"key\")]\n",
    "    text: Annotated[str, VectorStoreField(\"data\")]\n",
    "    embedding: Annotated[\n",
    "        list[float] | str | None,\n",
    "        VectorStoreField(\"vector\", dimensions=1536, embedding_generator=text_embedding),\n",
    "    ] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.embedding is None:\n",
    "            self.embedding = self.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the text into paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_paragraphs(text: str) -> list[str]:\n",
    "    \"\"\"Split text into paragraphs by empty lines.\"\"\"\n",
    "    paragraphs = [p.strip() for p in text.strip().split('\\n\\n') if p.strip()]\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the SK kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel()\n",
    "\n",
    "# Add Azure OpenAI services\n",
    "kernel.add_service(AzureChatCompletion(service_id=\"chat\", api_key=api_key, endpoint=endpoint, deployment_name=\"gpt-4.1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with InMemoryCollection(record_type=DocumentParagraph) as collection:\n",
    "    await collection.ensure_collection_exists()\n",
    "    \n",
    "    # Split mock documents into paragraphs\n",
    "    paragraphs = split_into_paragraphs(MOCK_DOCUMENTS)\n",
    "    print(f\"Loaded {len(paragraphs)} paragraphs into the vector store.\\n\")\n",
    "    \n",
    "    # Create DocumentParagraph objects and upsert into collection\n",
    "    document_items = [\n",
    "        DocumentParagraph(id=f\"para_{i}\", text=para)\n",
    "        for i, para in enumerate(paragraphs)\n",
    "    ]\n",
    "    \n",
    "    await collection.upsert(document_items)\n",
    "    print(\"Documents successfully indexed.\\n\")\n",
    "    \n",
    "    # Create a search function for the collection\n",
    "    kernel.add_function(\n",
    "        \"memory\",\n",
    "        collection.create_search_function(\n",
    "            function_name=\"recall\",\n",
    "            description=\"Recalls information from the document collection.\",\n",
    "            string_mapper=lambda x: x.record.text,\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    # Example 1: Direct template-based RAG query\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Example 1: Template-based RAG Query\")\n",
    "    print(\"=\" * 60)\n",
    "    result = await kernel.invoke_prompt(\n",
    "        function_name=\"rag_query_1\",\n",
    "        plugin_name=\"RAGPlugin\",\n",
    "        prompt=\"{{memory.recall 'machine learning'}} Based on the information above, what is machine learning?\",\n",
    "    )\n",
    "    print(result)\n",
    "    print()\n",
    "    \n",
    "    # Example 2: Let the LLM choose the function with auto function calling\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Example 2: LLM Auto Function Calling\")\n",
    "    print(\"=\" * 60)\n",
    "    result = await kernel.invoke_prompt(\n",
    "        function_name=\"rag_query_2\",\n",
    "        plugin_name=\"RAGPlugin\",\n",
    "        prompt=\"What is the Transformer architecture and why is it important?\",\n",
    "        arguments=KernelArguments(\n",
    "            settings=OpenAIChatPromptExecutionSettings(\n",
    "                function_choice_behavior=FunctionChoiceBehavior.Auto(),\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    print(result)\n",
    "    print()\n",
    "    \n",
    "    # Example 3: Another auto function calling query\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Example 3: Complex Query with RAG\")\n",
    "    print(\"=\" * 60)\n",
    "    result = await kernel.invoke_prompt(\n",
    "        function_name=\"rag_query_3\",\n",
    "        plugin_name=\"RAGPlugin\",\n",
    "        prompt=\"Compare and contrast computer vision and natural language processing.\",\n",
    "        arguments=KernelArguments(\n",
    "            settings=OpenAIChatPromptExecutionSettings(\n",
    "                function_choice_behavior=FunctionChoiceBehavior.Auto(),\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    print(result)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
