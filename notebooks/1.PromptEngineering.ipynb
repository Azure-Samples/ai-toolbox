{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa865137",
   "metadata": {},
   "source": [
    "## üéØ Prompt Engineering Fundamentals\n",
    "\n",
    "Welcome to the first session of our AI Workshop! In this notebook, we'll dive deep into **Prompt Engineering** - the art and science of crafting effective instructions for Large Language Models (LLMs).\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "By the end of this notebook, you will understand:\n",
    "- The fundamentals of prompt engineering\n",
    "- Different prompting strategies: Zero-Shot, One-Shot, and Few-Shot\n",
    "- How to format responses using examples\n",
    "- Best practices for structuring prompts with conversation roles\n",
    "- Practical applications in classification and conversational AI\n",
    "\n",
    "### üìö What is Prompt Engineering?\n",
    "Prompt engineering is the process of designing and optimizing text prompts to get the best possible responses from AI language models. It's like learning how to ask the right questions in the right way to get accurate, useful, and well-formatted answers.\n",
    "\n",
    "Think of it as the bridge between human intent and AI understanding - the better your prompts, the better your results!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45cb2b0",
   "metadata": {},
   "source": [
    "### üì¶ Installing Required Packages\n",
    "We'll install the OpenAI library for Azure OpenAI integration and Panel for interactive widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f658a-708f-406c-a1cb-95e3482ae760",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe5f658a-708f-406c-a1cb-95e3482ae760",
    "outputId": "a44c5457-94f4-4357-c66b-8682253aee0a"
   },
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba193cc-d8a0-4ad2-8177-380204426859",
   "metadata": {
    "id": "fba193cc-d8a0-4ad2-8177-380204426859"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    ")\n",
    "\n",
    "print(os.getenv(\"AZURE_OPENAI_ENDPOINT\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c68d8d",
   "metadata": {},
   "source": [
    "### üîë Setting up Azure OpenAI Client\n",
    "Here we initialize our connection to Azure OpenAI. Make sure you have set the following environment variables:\n",
    "- `AZURE_OPENAI_ENDPOINT`: Your Azure OpenAI service endpoint\n",
    "- `AZURE_OPENAI_KEY`: Your Azure OpenAI API key\n",
    "\n",
    "üí° **Pro Tip**: Never hardcode API keys in your code! Always use environment variables for security."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502cfc93-21e0-498f-9650-37bc6ddd514d",
   "metadata": {
    "id": "502cfc93-21e0-498f-9650-37bc6ddd514d"
   },
   "source": [
    "# üé≠ Few-Shot Learning: Teaching AI by Example\n",
    "\n",
    "## The Power of Examples in Prompt Engineering\n",
    "\n",
    "To obtain the model's response in a specific format, we have various options, but one of the most powerful is to use **Few-Shot Learning**. This involves presenting the model with pairs of user queries and example responses.\n",
    "\n",
    "### üìä Understanding Shot Types\n",
    "\n",
    "Large models like GPT respond remarkably well to the examples provided, adapting their responses to match the specified format and style. The terminology depends on the number of examples:\n",
    "\n",
    "- **üéØ Zero-Shot**: No examples provided - the model relies purely on its training and your instructions\n",
    "- **üéØ One-Shot**: A single example to demonstrate the desired format\n",
    "- **üéØ Few-Shot**: Multiple examples (typically 2-6) to establish a clear pattern\n",
    "\n",
    "### üéì Best Practices\n",
    "- **One shot is often enough** for most tasks\n",
    "- **Maximum of 6 shots** is recommended for optimal performance\n",
    "- **Remember**: Examples consume input tokens on every request\n",
    "- **Quality over quantity**: Better examples lead to better results\n",
    "\n",
    "Let's explore each approach with practical examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8344712-06d7-4c24-83d8-f36d62926e5e",
   "metadata": {
    "id": "a8344712-06d7-4c24-83d8-f36d62926e5e"
   },
   "outputs": [],
   "source": [
    "#Function to call the model.\n",
    "def return_OAIResponse(user_message, context):\n",
    "\n",
    "#As we can see, we‚Äôre adding the user‚Äôs question at the end of the prompt with the user role, so the model understands that this is a user request and not an instruction on how it should work.\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    # print(newcontext)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\", # model = \"deployment_name\".\n",
    "        messages=newcontext,\n",
    "        temperature=0,\n",
    "        max_tokens=800\n",
    "    )\n",
    "\n",
    "    #print(response)\n",
    "    # print(response.model_dump_json(indent=2))\n",
    "    # print(response.choices[0].message.content)\n",
    "\n",
    "    return (response.choices[0].message.content)\n",
    "    #return (response.choices[0].message[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b128db",
   "metadata": {},
   "source": [
    "### üîß Helper Function: Our AI Communication Bridge\n",
    "\n",
    "Before we start experimenting with different prompting techniques, let's create a reusable function that will handle our conversations with the AI model.\n",
    "\n",
    "This function will:\n",
    "1. Take your message and context (previous conversation)\n",
    "2. Format it properly for the AI model\n",
    "3. Send the request to Azure OpenAI\n",
    "4. Return the AI's response\n",
    "\n",
    "**Key Features:**\n",
    "- Automatically adds user role to messages\n",
    "- Uses consistent temperature settings for reproducible results\n",
    "- Handles the Azure OpenAI API communication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611d73d-9330-466d-b705-543667e1b561",
   "metadata": {
    "id": "f611d73d-9330-466d-b705-543667e1b561"
   },
   "source": [
    "## üéØ Zero-Shot Prompting: The Minimalist Approach\n",
    "\n",
    "**Zero-Shot prompting** is the simplest form of prompt engineering. We provide no examples - just a clear instruction about what the AI should do.\n",
    "\n",
    "### üîç What to Expect:\n",
    "- ‚úÖ **Correct information** based on the model's training data\n",
    "- ‚ùå **No specific formatting** - the model uses its default response style\n",
    "- üé≤ **Variable output format** - responses may vary in structure\n",
    "\n",
    "This approach works well when you need quick, accurate information but don't care about the specific format of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
    "outputId": "4c4a9f4f-67c9-4a11-837f-1a1fd6b516ff"
   },
   "outputs": [],
   "source": [
    "#zero-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are an expert in F1.'}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2010?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c5a333",
   "metadata": {},
   "source": [
    "### üìù Zero-Shot Example: F1 Championship Query\n",
    "Let's ask about F1 champions with minimal context - just telling the AI it's an F1 expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
    "outputId": "5278df23-8797-4dc2-9340-ac29c1318a9c"
   },
   "outputs": [],
   "source": [
    "#one-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2000 f1 championship?\n",
    "     Driver: Michael Schumacher.\n",
    "     Team: Ferrari.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2011?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290794cb",
   "metadata": {},
   "source": [
    "## üéØ One-Shot Prompting: Learning from a Single Example\n",
    "\n",
    "**One-Shot prompting** provides exactly one example to show the AI the desired format. This is often the sweet spot between simplicity and control.\n",
    "\n",
    "### üîç What to Expect:\n",
    "- ‚úÖ **Structured response** following your example format\n",
    "- ‚úÖ **Consistent formatting** across multiple queries\n",
    "- ‚úÖ **Efficient token usage** - only one example needed\n",
    "\n",
    "Notice how we embed the example directly in the system message. This teaches the AI the pattern we want to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c454a8-181b-482b-873a-81d6ffde4674",
   "metadata": {
    "id": "32c454a8-181b-482b-873a-81d6ffde4674"
   },
   "source": [
    "## üéØ Few-Shot Prompting: Multiple Examples for Complex Patterns\n",
    "\n",
    "For more complex formats or when working with smaller/less capable models, **Few-Shot prompting** with multiple examples can be very effective.\n",
    "\n",
    "### üîç When to Use Few-Shot:\n",
    "- üìã **Complex formatting requirements**\n",
    "- ü§ñ **Smaller or specialized models**\n",
    "- üéØ **High consistency needs**\n",
    "- üìä **Structured data extraction**\n",
    "\n",
    "Let's see how multiple examples reinforce the pattern and improve consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
    "outputId": "a6f90f5d-6d68-4b3d-ccb5-5848ae4e3e62"
   },
   "outputs": [],
   "source": [
    "#Few shots\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Bettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
    "outputId": "75f63fe3-0efc-45ed-dd45-71dbbb08d7a6"
   },
   "outputs": [],
   "source": [
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fdb19",
   "metadata": {},
   "source": [
    "### üîÑ Testing Pattern Consistency\n",
    "Let's test if our few-shot examples create a consistent pattern by asking about a different year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86",
   "metadata": {
    "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86"
   },
   "source": [
    "## üé≠ Advanced Few-Shot: Using Conversation Roles\n",
    "\n",
    "### üöÄ The Recommended Approach\n",
    "\n",
    "While embedding examples in system messages works, the **proper way** is to use OpenAI's conversation roles. This approach is more effective because:\n",
    "\n",
    "- üéì **Natural Learning**: The model learns from realistic conversation patterns\n",
    "- üîÑ **Better Context Understanding**: Roles help the AI understand the conversation flow\n",
    "- ‚ö° **Improved Performance**: More aligned with how the model was trained\n",
    "\n",
    "### üéØ Role Structure:\n",
    "- **System**: Sets the context and rules\n",
    "- **User**: Represents the human asking questions  \n",
    "- **Assistant**: Shows the AI's desired response format\n",
    "\n",
    "This mimics a real conversation, making the model's learning more effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
    "outputId": "868d2040-ca3c-4a47-a1e8-1e08d581191d"
   },
   "outputs": [],
   "source": [
    "#Recomended solution\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are and expert in f1.\\n\\n'},\n",
    "    {'role':'user', 'content':'Who won the 2010 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Sebastian Bettel. \\nTeam: Red Bull. \\nPoints: 256. \"\"\"},\n",
    "    {'role':'user', 'content':'Who won the 2009 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Jenson Button. \\nTeam: BrawnGP. \\nPoints: 95. \"\"\"},\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b373dd",
   "metadata": {},
   "source": [
    "### üåü Role-Based Few-Shot Example\n",
    "Notice how we structure this as a realistic conversation with clear roles and consistent formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f6b42-f351-496b-a7e8-1286426457eb",
   "metadata": {
    "id": "ac6f6b42-f351-496b-a7e8-1286426457eb"
   },
   "source": [
    "## üìã Alternative Approach: Instruction-Based Prompting\n",
    "\n",
    "### üîÑ Instructions vs Examples\n",
    "\n",
    "Instead of learning from examples, we can provide explicit instructions about format and content. \n",
    "\n",
    "### üéØ Key Difference:\n",
    "- **Examples (Few-Shot)**: The model **learns** patterns during inference\n",
    "- **Instructions**: The model **follows** explicit rules and formatting guidelines\n",
    "\n",
    "Both approaches work, but they operate differently:\n",
    "- Instructions are more explicit and rule-based\n",
    "- Examples create implicit learning and pattern recognition\n",
    "\n",
    "Let's see instruction-based prompting in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
    "outputId": "4c970dde-37ff-41a9-8d4e-37bb727f47a6"
   },
   "outputs": [],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\"\"\"You are and expert in f1.\n",
    "    You are going to answew the question of the user giving the name of the rider,\n",
    "    the name of the team and the points of the champion, following the format:\n",
    "    Drive:\n",
    "    Team:\n",
    "    Points: \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fdf7b6",
   "metadata": {},
   "source": [
    "### üìù Instruction-Based Example\n",
    "Here we explicitly tell the AI exactly what information to include and how to format it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KNDL1GzVngyL",
   "metadata": {
    "id": "KNDL1GzVngyL"
   },
   "outputs": [],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are classifying .\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Bettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e49bd9",
   "metadata": {},
   "source": [
    "### üß™ Comparison Test\n",
    "Let's see how this compares to our few-shot approach with the same query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qZPNTLMPnkQ4",
   "metadata": {
    "id": "qZPNTLMPnkQ4"
   },
   "source": [
    "# üè∑Ô∏è Practical Application: Sentiment Classification\n",
    "\n",
    "## Real-World Use Case: Product Review Analysis\n",
    "\n",
    "Let's apply our few-shot learning to a practical business problem: **sentiment analysis** of product reviews.\n",
    "\n",
    "### üéØ Business Context:\n",
    "- E-commerce companies need to quickly categorize customer feedback\n",
    "- Manual review analysis is time-consuming and inconsistent\n",
    "- AI can provide fast, consistent sentiment classification\n",
    "\n",
    "### üìä Classification Categories:\n",
    "- **Positive**: Happy, satisfied customers\n",
    "- **Negative**: Disappointed, unsatisfied customers  \n",
    "- **Neutral**: Mixed or unclear sentiment\n",
    "\n",
    "Watch how few-shot examples help the AI understand subtle sentiment nuances!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ejcstgTxnnX5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejcstgTxnnX5",
    "outputId": "4b91cc73-18f6-4944-a46b-806b02b7becb"
   },
   "outputs": [],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in reviewing product opinions and classifying them as positive or negative.\n",
    "\n",
    "     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n",
    "     Setiment: Positive\n",
    "\n",
    "     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n",
    "     Sentiment: Negative.\n",
    "\n",
    "     I wouldn't know what to say, my son uses it, but he doesn't love it.\n",
    "     Sentiment: Neutral\n",
    "     \"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ed9b9",
   "metadata": {},
   "source": [
    "### üé≠ Sentiment Analysis in Action\n",
    "Here we provide three examples showing positive, negative, and neutral sentiment patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_user=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an OrderBot in a fastfood restaurant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"I have only 10 dollars, what can I order?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"We have the fast menu for 7 dollars.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Perfect! Give me one! \"}\n",
    "]\n",
    "print(return_OAIResponse(\"\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6db54a",
   "metadata": {},
   "source": [
    "### ü§ñ OrderBot Conversation Example\n",
    "Notice how we pass an empty string as the user message - the conversation context provides all the information needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba10e3f",
   "metadata": {},
   "source": [
    "# üçî Conversational AI: Building a Restaurant OrderBot\n",
    "\n",
    "## Multi-Turn Conversation Design\n",
    "\n",
    "Our final example demonstrates how to build conversational AI that maintains context across multiple exchanges.\n",
    "\n",
    "### üéØ Key Concepts:\n",
    "- **Context Preservation**: Each message builds on previous conversation\n",
    "- **Role Consistency**: The AI maintains its character as an OrderBot\n",
    "- **Natural Flow**: Conversation feels human-like and helpful\n",
    "\n",
    "### üîç Conversation Structure:\n",
    "1. **System**: Defines the AI's role and behavior\n",
    "2. **User**: Customer's initial question  \n",
    "3. **Assistant**: Helpful response with suggestions\n",
    "4. **User**: Customer makes a decision\n",
    "5. **Assistant**: Confirms and processes the order\n",
    "\n",
    "This simulates a real restaurant ordering experience!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b32c72",
   "metadata": {},
   "source": [
    "# üéì Summary and Key Takeaways\n",
    "\n",
    "## What We've Learned\n",
    "\n",
    "Congratulations! You've just mastered the fundamentals of prompt engineering. Let's recap the key concepts:\n",
    "\n",
    "### üéØ Prompting Strategies\n",
    "1. **Zero-Shot**: Quick and simple, but no format control\n",
    "2. **One-Shot**: Perfect balance of simplicity and structure  \n",
    "3. **Few-Shot**: Best for complex patterns and consistent formatting\n",
    "\n",
    "### üèÜ Best Practices\n",
    "- ‚úÖ Use conversation roles (system, user, assistant) for better results\n",
    "- ‚úÖ Provide clear, specific examples that match your desired output\n",
    "- ‚úÖ Keep examples concise but representative\n",
    "- ‚úÖ Test your prompts with multiple inputs to ensure consistency\n",
    "\n",
    "### üöÄ Real-World Applications\n",
    "- **Content Generation**: Structured responses for reports, summaries\n",
    "- **Classification**: Sentiment analysis, categorization, tagging\n",
    "- **Conversational AI**: Chatbots, virtual assistants, customer service\n",
    "- **Data Extraction**: Structured information from unstructured text\n",
    "\n",
    "### üîÆ Next Steps\n",
    "In our next notebook, we'll explore:\n",
    "- **RAG (Retrieval-Augmented Generation)**: Connecting AI to external knowledge\n",
    "- **LLM Agents**: Building autonomous AI systems that can take actions\n",
    "- **Multi-Agent Systems**: Coordinating multiple AI agents for complex tasks\n",
    "\n",
    "Keep practicing with different prompting strategies - the more you experiment, the better you'll become at crafting effective prompts!\n",
    "\n",
    "---\n",
    "\n",
    "*Happy prompting! üéâ*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
